######################################
##      Globals                     ##
######################################

global:
  #image settings
  image:
    #repository the docker repository which will have the image
    repository: docker.repository.axway.com/amplifyintegration-docker-prod/1.4.0
    #pullPolicy the image pull policy
    pullPolicy: IfNotPresent
    #imagePullSecrets secret that stores credentials for access to a registry for docker images
    imagePullSecrets:
      - name: ampint-docker-artifactory

  # Chose here the HOSTNAME for your dataplane:
  #    it will be: appEnv.external_domain (for example here: env.your-dataplane-domain.com)
  appEnv: "env"
  #external_domain domain name for environment
  external_domain: ""

  # claimName a reference to the file share claim name
  claimName: sharedstorage-claim
  # volumeStorageName the volume name of the persistent fileshare
  volumeStorageName: fileshare-storage
  # clusterKey is obtained from the Control Plane User Interface
  clusterKey: ""

######################################
##      Common Chart                ##
######################################

common:
  # enabled means the common chart is enabled
  enabled: false

  ######################################
  ##      Environment config          ##
  ######################################
  cert_name: "mykey.p12" #domain certificate in pkcs12 format

  # Select here the emails targets for the dataplane (for example for admin email notification)
  # if you don't want to use put any dummy email and usetls and authentications "false"
  admin_email: "" #for example: "myadminemail@example.com"
  dxchange_email_host: "" # Email host name -for example smtp.office365.com
  dxchange_email_port: "" #port number for example 587
  dxchange_email_tomailid: "" # for example "myadminemail@example.com"
  dxchange_email_usetls: false # true if it using tls else false
  dxchange_email_username: "" #  for example "myadminemail@example.com"
  dxchange_email_authentication: false # true if email authentication required


  ######################################
  ##        General conditions        ##
  ######################################

  # acceptGeneralConditions In order to install the Data Plane, you need to set acceptGeneralConditions to "yes":
  # You hereby accept that the Axway Products and/or Services shall be governed exclusively by the Axway General Terms and Conditions located at Axway General Conditions,
  # https://www.axway.com/sites/default/files/Legal_documents/License_general_conditions/Axway_General_Conditions_version_april_2014_eng_(France).pdf
  # unless an agreement has been signed with Axway in which case such agreement shall apply.
  acceptGeneralConditions: "yes"

  ######################################
  ##           Secrets                ##
  ######################################
  # This block generates secrets that will be used by the other Helm charts
  # ALL SECRETS HAVE TO BE ENCODED into base 64 (to avoid YAML issues):
  #    printf 'myvaluetoencode' | base64 -w 0

  # cert-p12 secret settings
  # All three values of this "cert-p12" secret need to be the same: the password for your PKCS 12 store (certificate + key for your dedicated Data Plane hostname)
  #      If you already have your PKCS 12 already, set the password you used to create it, or else select one now
  serverCertPassword: ""       # base 64 encoded PKCS 12 password:     printf 'mystorepassword' | base64 -w 0
  sftpServerCertPassword: ""   # base 64 encoded PKCS 12 password:     printf 'mystorepassword' | base64 -w 0
  serverTruststorePassword: "" # base 64 encoded PKCS 12 password:     printf 'mystorepassword' | base64 -w 0

  # ampint-docker-artifactory secret settings
  # This secret is the image pull secrets used by all the charts
  # For a customer: create a service account of type "Client Secret" on the Amplify Repository, and generate the .dockerconfigjson value with:
  #      REGISTRY_USERNAME= # credentials from your service account
  #      REGISTRY_PASSWORD= # credentials from your service account
  #      REGISTRY_SERVER=docker.repository.axway.com
  #      kubectl create secret docker-registry ampint-docker-artifactory --docker-server="${REGISTRY_SERVER}" --docker-username="${REGISTRY_USERNAME}" --docker-password="${REGISTRY_PASSWORD}" --dry-run=client --output=jsonpath="{.data.\.dockerconfigjson}"
  dockerconfigjson: ""

  # ampint-frommail secret settings
  # This secret allow the Data Plane to send emails from a valid email address that you control. Fill in with valid, preexisting credentials
  fromMailId: ""       # base 64 encoded credentials:     printf 'myemail@example.com' | base64 -w 0
  fromMailPassword: "" # base 64 encoded credentials:     printf 'mypassword' | base64 -w 0

  # management-center-credentials secret settings
  # Select here the credentials to use for the optional Hazelcast UI (a service only used for debug purpose)
  # whoever have access for data-plane they can only access management-center UI.
  # once deployment is completed, if you want to access use kubectl port-forward command.
  # kubectl port-forward svc/<management-center-svc-name> 9090:8080 -n <namespace>
  mcAdminUser: "YWRtaW4=" # the default user is admin, please keep this one for now
  mcAdminPassword: "" # base 64 encoded password to configure:     printf 'password14' | base64 -w 0

  ####################################################
  ##   Persistence Setup
  ####################################################

  #common settings for persistence of data
  persistence:
    # claimRequestCapacity the claim's requested storage capacity size
    claimRequestCapacity: 50Gi
    # volumeCapacity the volume's storage capacity size
    volumeCapacity: 50Gi

  ## Azure Files ##
  #If you are using Amazon EFS, modify settings in here
  azfiles:
    enabled: false # set it to true
    resourceGroup: "" # where AKS cluster is installed ex: prf01-ampint-ddp-rg01
    storageAccountName: "" # Storage account name where file storage created ex: prf02ampintddpsa01
    fileshareName: "" # Name of your fileshare tst01ampintdd02afs01
    # azurefs-secret this secret is used to get access to azure file system storage use storage account name and its key values.
    azureStorageAccountName: ""  # Storage account name where file storage created ex: prf02ampintddpsa01 base64 encoded
    azureStorageAccountKey: ""   # Storage account key1 value base 64 encoded password to configure: printf 'password14' | base64 -w 0

  ## Amazon EFS ##
  #If you are using Amazon EFS, modify settings in here
  efs:
    enabled: false # set it to true
    #volumeHandle the volume handle name. Composition of EFS "file system id::access point id". example fs-xxxxxxxxx::fsap-xxxxxxxxx
    volumeHandle: "fs-xxxxxxxxxxx::fsap-xxxxxxxxxxx"

  ## Standard NFS ##
  #If you are using Standard NFS, modify settings in here
  nfs:
    enabled: false # set it to true
    server: "" # example - fs-003ea2414e03f749d.efs.ap-south-1.amazonaws.com # put your nfs server info here
    path: / # if you are not using / but a subdirectory, then make sure it already exists. Make sure gid 1001 is allowed to rw in that directory (e.g. perform a chown 1001:1001 . in your NFS)

    # use csi or nfs depending on how you want to mount the volume directly as nfs or through the nfs csi driver
    # if you use csi, make sure you have installed the csi driver:
    #       helm repo add csi-driver-nfs https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
    #       helm install csi-driver-nfs csi-driver-nfs/csi-driver-nfs --namespace kube-system --version v4.1.0
    mode: csi
    mountOptions:
      - nfsvers=4.1 # put your mount options here, as a yaml list

  #####################################################
  ##   [optional] Audits configuration     ##
  ################/####################################
  enable_audits: "" #true/false generating step level audits for a transaction
  enable_transaction_logs: "" #true/false Txn logs for an event

######################################
##      Ingress Chart               ##
######################################
##NOTE: If you don't want to use https,http,sftp make it false, it won't deploy.
ingress:
  enabled: false
  image:
    repository: envoyproxy
    tag: v1.28.0

  # Use the following block if you have Calico and want to use its network policies # You will need the Calico API server to be installed as well
  # if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false
    # reference the source IPs allowed into envoy ingress
    subnetEntityRule:
      # use this to reference a (preexisting) networkset by label
      selector: role == 'nodes-subnet-vpc-cidr'
      # or uncomment this to directly reference IP cidr instead
      #nets:
      #  - 10.0.0.0/24 # put your subnet cidr here

  #if psp is setup in dataplane make it true, if not make it false
  podSecurityPolicy:
    enabled: false

  #Env loglevel debug or info
  env:
    LOGLEVEL: info
  timeouts:
    # Loadbalancer timeout higher than request to allow for clean closing of request.
    loadbalancer: 3700
    maxDuration: 3600s
    idleTimeout: 3600s
    connectTimeout: 15s

  # CPU and Resource and autoscaling
  resources:
    limits:
      cpu: 100m
      memory: 100Mi
    requests:
      cpu: 80m
      memory: 80Mi
  # you can provide max replica value as per your node configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  # Update your node affinity configuration as per node configurations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
  # if you want use multi AZ for pods, you need to setup infra node affinity as per need.
  # if you want to use multi AZ(pods in particular zone) enable zone topology key, if you want to use one pod in one node enable hostname topology key
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - ingress
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname
  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1

######################################
##      Hazelcast Chart             ##
######################################

hazelcast:
  enabled: false
  image:
    name: hazelcast-server
    buildTag: ampint-1.4_2023-11-29T07_38_42Z  # provide the build tag here
  persistence:
    #claimTemplateRequestStorage the volumeClaimTemplate's requested storage capacity size
    claimTemplateRequestStorage: 50Gi
    #claimTemplateStorageClass class that will dynamically create storage on desired cloud platform
    #For AWS set this value to gp3
    #For Azure set this value to managed-csi
    #For NFS see https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner

    #For the Azure data Plane, if you are using, enable it and disable the AWS Data plane claimTemplateStorageClass
    claimTemplateStorageClass: "managed-csi"

    # For the AWS dataplane if you are using, enable it and disable the AZURE Data plane claimTemplateStorageClass
  #    claimTemplateStorageClass: "gp3"

  # Use the following block if you have Calico and want to use its network policies
  # You will need the Calico API server to be installed as well
  #if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false

  # if psp is setup in dataplane make it true, if not make it false
  # only applied if serviceAccount is enabled # will bind that service Account to the "restricted" psp # as no special capabilities are required for this service
  podSecurityPolicy:
    enabled: false

  #JAVA_OPTS, Resource CPU and Memory
  javaOpts: "-XX:MinRAMPercentage=25 -XX:MaxRAMPercentage=75"
  resources:
    limits:
      cpu: 600m
      memory: 500Mi
    requests:
      cpu: 450m
      memory: 380Mi

  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  # Update your node affinity configuration as per node configurations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dxhazelcasta
    #                  - dxhazelcastb
    #                  - dxhazelcastc
    # if you want use multi AZ for pods, you need to setup infra node affinity as per need.
    # if you want to use multi AZ(pods in particular zone) enable zone topology key, if you want to use one pod in one node enable hostname topology key
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - hazelcast
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname

  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "hazelcast"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1
######################################
##      Inbound-Worker Chart        ##
######################################

inbound-worker:
  enabled: false
  image:
    name: inbound-worker
    buildTag: ampint-1.4_2023-11-29T07_38_42Z  # provide your build tag here
  # Use the following block if you have Calico and want to use its network policies
  # You will need the Calico API server to be installed as well

  # host_name which should match the common name in the server_cert_path
  host_name: "xxxxxx"    #eg:- ampint-dev01-dd01.dxchange.cloud

  # if you use hostPath for high performance, FOR this you need to install hostpath script which is updated in tgz file.
  # by default transaction-logs and transaction-data directly moves to fileshare/efs. if you make hostpath "true" it moves to node disk/volume then moves to efs/fileshare.
  hostPath:
    enabled: false

  #if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false
    # reference the targets the inbound-worker is allowed to reach
    outboundRule:
      # use this to reference a (preexisting) networkset
      selector: role == 'any-address'
      # or uncomment this to directly reference IP cidr instead
      #nets:
      #  - 0.0.0.0/0 # put your subnet cidr here

  #if psp is setup in dataplane make it true, if not make it false
  # only applied if serviceAccount is enabled # will bind that service Account to the "restricted" psp # as no special capabilities are required for this service
  podSecurityPolicy:
    enabled: false

  #SFTP and HTTPS Connections
  # if you want use HTTPS,HTTP,SFTP connections, make it true
  sftp_enable: "false"
  http_enable: "false"
  https_enable: "false"

  #JAVA_OPTS, Resource CPU and Memory
  javaOpts: "-XX:MinRAMPercentage=25 -XX:MaxRAMPercentage=75"
  resources:
    limits:
      cpu: 400m
      memory: 400Mi
    requests:
      cpu: 300m
      memory: 300Mi
  # you can provide max replica value as per your node configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5

  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  # Update your node affinity configuration as per node configurations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
    # if you want use multi AZ for pods, you need to setup infra node affinity as per need.
    # if you want to use multi AZ(pods in particular zone) enable zone topology key, if you want to use one pod in one node enable hostname topology key
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - inbound-worker
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname

  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1
######################################
##      Orchestrator Chart          ##
######################################

orchestrator:
  enabled: false
  image:
    name: orchestrator
    buildTag: ampint-1.4_2023-11-29T07_38_42Z  # provide your build tag here
  # Use the following block if you have Calico and want to use its network policies
  # You will need the Calico API server to be installed as well
  #if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false
    # reference the targets the orchestrator is allowed to reach
    outboundRule:
      # use this to reference a (preexisting) networkset
      selector: role == 'any-address'
      # or uncomment this to directly reference IP cidr instead
      #nets:
      #  - 0.0.0.0/0 # put your subnet cidr here

  #if psp is setup in dataplane make it true, if not make it false
  # only applied if serviceAccount is enabled # will bind that service Account to the "restricted" psp # as no special capabilities are required for this service
  podSecurityPolicy:
    enabled: false

  # if you use hostPath for high performance, FOR this you need to install hostpath script which is updated in tgz file.
  # by default transaction-logs and transaction-data directly moves to fileshare/efs. if you make hostpath "true" it moves to node disk/volume then moves to efs/fileshare.
  hostPath:
    enabled: false

  # max_executions_limit number of parallel executions allowed
  max_executions_limit: "20"

  #JAVA_OPTS, Resource CPU and Memory
  javaOpts: "-XX:MinRAMPercentage=25 -XX:MaxRAMPercentage=75 -XX:+DisableExplicitGC"
  resources:
    limits:
      cpu: 600m
      memory: 500Mi
    requests:
      cpu: 450m
      memory: 380Mi
  # you can provide max replica value as per your node configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5

  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  # Update your node affinity configuration as per node configurations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
    # if you want use multi AZ for pods, you need to setup infra node affinity as per need.
    # if you want to use multi AZ(pods in particular zone) enable zone topology key, if you want to use one pod in one node enable hostname topology key
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - orchestrator
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname

  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1

######################################
##      Predeploy Chart             ##
######################################

predeploy:
  enabled: false
  image:
    name: cache-copy-job
    buildTag: ampint-1.4_2023-11-29T07_38_42Z #provide your build tag here

  # If your using azure data plane, forceclosehandles enable "true", if not make it "false"
  # NOTE: if the predeploy job is not working as excepted, need to run the below command az storage share close-handle manually in terminal
  # Example: az storage share close-handle --account-name prf01ampintddpsa01 --name prf01ampintddpafs01 --connection-string "DefaultEndpointsProtocol=https;AccountName=prf01ampintddpsa01;AccountKey=uu8hjJLKYlKcOaks4BcsYiXjRjjYfmbhEdfdfdfdfedfefIaAsJc4XFsdxDZPFUXtgfPfYotyR7vY+AStZtu1sw==;EndpointSuffix=core.windows.net" --close-all --recursive
  # Next get into inbound-worker shell and delete the event-cache and component-cache, then rerun the deployment once again
  azureFiles:
    # when using azure files for the backing shared persistent volume, with the SMB protocole, you can use this option to facilitate the upgrade
    forceCloseHandles:
      enabled: false
      # the storage account for your fileshare
      storageAccount: "NA"  #eg: prf01ampintddpsa01
      # the fileshare name
      fileshare: "NA"  #eg: prf01ampintddpafs01
      # the client id for the managed identity, assigned to your VM Scaling sets
      # it must have the role "Storage File Data Privileged Reader" (scope "storage", resource: your storage account)
      vmssManagedIdentityClientId: "NA" #eg: xxxfaee2f-6186-xx2c-babe-2f5d953914558

  #Node affinity and tolerations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

######################################
##      Sink-agent Chart             ##
######################################

sink-agent:
  enabled: false
  image:
    name: sink-agent
    buildTag: ampint-1.4_2023-11-29T07_38_42Z  #provide your build tag here

  # Use the following block if you have Calico and want to use its network policies # You will need the Calico API server to be installed as well
  #if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false
    # reference the targets the inbound-worker is allowed to reach
    outboundRule:
      # use this to reference a (preexisting) networkset
      selector: role == 'any-address'
      # or uncomment this to directly reference IP cidr instead
      #nets:
      #  - 0.0.0.0/0 # put your subnet cidr here

  #if psp is setup in dataplane make it true, if not make it false
  # only applied if serviceAccount is enabled # will bind that service Account to the "restricted" psp # as no special capabilities are required for this service
  podSecurityPolicy:
    enabled: false

  # JAVA_OPTS, Resource CPU and Memory
  # The values we provide for cpu and memory is a bare minimum resource requirements, You can tune cpu and memory as per your machine requirements.
  javaOpts: "-XX:MinRAMPercentage=25 -XX:MaxRAMPercentage=75"
  resources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 80m
      memory: 150Mi

  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
    # if you want use multi AZ for pods, you need to setup infra node affinity as per need.
    # if you want to use multi AZ(pods in particular zone) enable zone topology key, if you want to use one pod in one node enable hostname topology key
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - sink-agent
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname

  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1

######################################
##      PEP Server Chart            ##
######################################
pep-server:
  enabled: true
  image:
    name: pep-server
    buildTag: ampint-1.4_2023-11-29T07_38_42Z

  calicoNetpol:
    enabled: false

  #if psp is setup in dataplane make it true, if not make it false
  podSecurityPolicy:
    enabled: false

  #JAVA_OPTS, Resource CPU and Memory
  javaOpts: "-XX:MinRAMPercentage=50 -XX:MaxRAMPercentage=90"
  resources:
    limits:
      cpu: 500m
      memory: 500Mi
    requests:
      cpu: 500m
      memory: 500Mi

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"
######################################
##      Management-Center Chart     ##
######################################

management-center:
  enabled: false
  image:
    name: management-center
    buildTag: 5.3.0
  # Use the following block if you have Calico and want to use its network policies
  # You will need the Calico API server to be installed as well
  #if calicoNetpol is setup in dataplane make it true, if not make it false
  calicoNetpol:
    enabled: false
  #if psp is setup in dataplane make it true, if not make it false
  # PodSecurityPolicy # only applied if serviceAccount is enabled # will bind that service Account to the "restricted" psp # as no special capabilities are required for this service
  podSecurityPolicy:
    enabled: false

  # JAVA_OPTS, Resource CPU and Memory
  # The values we provide for cpu and memory is a bare minimum resource requirements, You can tune cpu and memory as per your machine requirements.

  javaOpts: "-XX:MinRAMPercentage=25 -XX:MaxRAMPercentage=75"
  resources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 80m
      memory: 150Mi
  # you can provide max replica value as per your node configuration
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 1
  # you can use affinity and tolerations to handle node taints. Here is an example of
  # how to use them to put them on nodes with the label pool=mypool and the taint taintkey=taintvalue
  # Update your node affinity configuration as per node configurations
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pool
                operator: In
                values:
                  - dataplane
  #    podAntiAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        - labelSelector:
  #            matchExpressions:
  #              - key: dplane
  #                operator: In
  #                values:
  #                  - management-center
  #          topologyKey: topology.kubernetes.io/zone
  #          topologyKey: kubernetes.io/hostname
  tolerations:
    - key: "dxchangeapps"
      operator: "Equal"
      value: "dataplane"
      effect: "NoSchedule"

  # if you are using podantiaffinity uncomment
#  podDisruptionBudget:
#    enabled: false
#    minPods: 1